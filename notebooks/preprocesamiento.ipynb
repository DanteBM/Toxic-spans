{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trial = pd.read_csv(\"../data/tsd_trial.csv\")\n",
    "print(data_trial.shape)\n",
    "data_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7939, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>Another fool pipes in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...</td>\n",
       "      <td>So if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>Any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>This idiotic. Use the surplus to pay down the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[106, 107, 108, 109, 110, 169, 170, 171, 172, ...</td>\n",
       "      <td>Who is this \"we\" of which you speak? Are you r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "0     [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                          [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                          [0, 1, 2, 3]   \n",
       "3             [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                          [32, 33, 34, 35, 36, 37, 38]   \n",
       "...                                                 ...   \n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...   \n",
       "7936  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "7937                            [5, 6, 7, 8, 9, 10, 11]   \n",
       "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...   \n",
       "\n",
       "                                                   text  \n",
       "0     Another violent and aggressive immigrant killi...  \n",
       "1     I am 56 years old, I am not your fucking junio...  \n",
       "2                     Damn, a whole family. Sad indeed.  \n",
       "3     What a knucklehead. How can anyone not know th...  \n",
       "4     \"who do you think should do the killing?\"\\n\\nA...  \n",
       "...                                                 ...  \n",
       "7934                             Another fool pipes in.  \n",
       "7935  So if a restaurant owner puts up a sign saying...  \n",
       "7936  Any faith that can't stand up to logic and rea...  \n",
       "7937  This idiotic. Use the surplus to pay down the ...  \n",
       "7938  Who is this \"we\" of which you speak? Are you r...  \n",
       "\n",
       "[7939 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"../data/tsd_train.csv\")\n",
    "print(data_train.shape)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8629, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_trial, data_train])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hab√≠a solamente cinco textos repetidos. \n",
    "\n",
    "Se usar√° `tsd_train.csv` para entrenar y `tsd_trial` para validaci√≥n\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alfabeto\n",
    "\n",
    "Vendr√≠a bien conocer que s√≠mbolos hay en los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjuntos = data_train.text.agg(set)\n",
    "alfabeto = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '}',\n",
       " '~',\n",
       " '\\x7f',\n",
       " '\\xa0',\n",
       " '¬´',\n",
       " '¬¨',\n",
       " '¬∑',\n",
       " '¬ª',\n",
       " '√©',\n",
       " '√™',\n",
       " '√Ø',\n",
       " '√≥',\n",
       " '√º',\n",
       " ' ª',\n",
       " 'Àà',\n",
       " 'Õû',\n",
       " '\\u2004',\n",
       " '\\u200b',\n",
       " '‚Äì',\n",
       " '‚Äî',\n",
       " '‚Äï',\n",
       " '‚Äò',\n",
       " '‚Äô',\n",
       " '‚Äú',\n",
       " '‚Äù',\n",
       " '‚Ä¢',\n",
       " '‚Ä¶',\n",
       " '‚Ñ¢',\n",
       " '‚ñÄ',\n",
       " '‚ò†',\n",
       " '‚ò≠',\n",
       " '‚òπ',\n",
       " '‚öΩ',\n",
       " '‚öæ',\n",
       " '‚ú≠',\n",
       " 'Ô∏è',\n",
       " 'üÜò',\n",
       " 'üëé',\n",
       " 'üíÄ',\n",
       " 'üí•',\n",
       " 'üí®',\n",
       " 'üî•',\n",
       " 'üòÅ',\n",
       " 'üòÇ',\n",
       " 'üòÖ',\n",
       " 'üòÜ',\n",
       " 'üòà',\n",
       " 'üòâ',\n",
       " 'üòä',\n",
       " 'üòú',\n",
       " 'üòû',\n",
       " 'üò°',\n",
       " 'üò¨',\n",
       " 'üòµ',\n",
       " 'üôÑ',\n",
       " 'ü§•'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,item in conjuntos.iteritems():\n",
    "    alfabeto |= item\n",
    "\n",
    "alfabeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alfabeto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparte del abecedario, tenemos algunos s√≠mbolos que se usan con relativa frecuencia en internet.\n",
    "\n",
    "Sin embargo, tambi√©n notamos que hay caracteres raros como las comillas dobles, guiones con sus variantes, etc. Tambi√©n hay que notar que hay emojis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulario\n",
    "\n",
    "Para obtener el vocabulario, es necesario realizar un preprocesamiento a los textos, esto incluye:\n",
    "* sustituir min√∫sculas\n",
    "* quitar emojis\n",
    "* ¬øquitar caracteres raros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar(texto):\n",
    "    texto = texto.lower() #min√∫sculas\n",
    "    texto = re.sub(\"[\\W_]\", \" \", texto) #car√°cteres raros\n",
    "    texto = re.sub(\"\\s+\", \" \", texto) # colapsando espaciados\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another violent and aggressive immigrant killing a innocent and intelligent US Citizen.... Sarcasm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data_train.text[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'another violent and aggressive immigrant killing a innocent and intelligent us citizen sarcasm'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_preprocesado = data_train.text.apply(limpiar)\n",
    "\n",
    "texto_tokenizado = texto_preprocesado.apply(str.split)\n",
    "\n",
    "vocabulario = set()\n",
    "for index, lista in texto_tokenizado.iteritems():\n",
    "    vocabulario |= set(lista)\n",
    "\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento\n",
    "\n",
    "Vamos a obtener el texto que se ha considerado como t√≥xico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_span(span):\n",
    "    span = re.sub(\"\\s\",\"\",span[1:-1])\n",
    "    if span:\n",
    "        lista = span.split(\",\")\n",
    "        lista = [int(index) for index in lista]\n",
    "    else:\n",
    "        lista = []\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"spans\"] = data_train[\"spans\"].apply(procesar_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_texto_toxico(row):\n",
    "    toxico = []\n",
    "    if row.spans: # Hay texto marcado como toxico\n",
    "        diffs = np.diff(row.spans, prepend=row.spans[0]-1) #prepend para que el primer diff sea uno\n",
    "        toxico = []\n",
    "        indices_inicios = np.argwhere(diffs != 1).ravel() # indices de los inicios de las sigs palabras\n",
    "\n",
    "        i = row.spans[0]\n",
    "        for indice_next in indices_inicios:\n",
    "            j = row.spans[indice_next-1] # fin de la anterior\n",
    "            parte_toxica = row.text[i:j+1]\n",
    "            toxico.append(parte_toxica)\n",
    "            i = row.spans[indice_next]\n",
    "            \n",
    "        # √öltima parte\n",
    "        j = row.spans[-1]\n",
    "        parte_toxica = row.text[i:j+1]\n",
    "        toxico.append(parte_toxica)\n",
    "\n",
    "    return toxico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitando espacios de los tramos t√≥xicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quitar_espacios_de_spans(row):\n",
    "    toxico = obtener_texto_toxico(row)\n",
    "    toxic_span = \"\".join(toxico) # juntar texto t√≥xico\n",
    "    toxic_match = set(re.findall(r\"\\W\", toxic_span)) # encontrar cosas que no son letras, n√∫meros o gui√≥n bajo\n",
    "    # Inicializaci√≥n\n",
    "    buenos = row.spans\n",
    "    indices = []\n",
    "    \n",
    "    for extra√±o in toxic_match: # Si no hay nada en toxic_match, no se itera\n",
    "        extra√±o = re.escape(extra√±o) # escapando posibles caracteres con interpretaci√≥n RegEx\n",
    "        if extra√±o == \"\\ \":\n",
    "            indice = re.finditer(extra√±o, toxic_span) \n",
    "            indices = [i.start() for i in indice] # √çndices de espacios en el texto\n",
    "    if indices:\n",
    "        por_quitar = [row.spans[i] for i in indices] # spans t√≥xicos que son espacios\n",
    "        buenos = [i for i in row.spans if i not in por_quitar] # filtrando\n",
    "            \n",
    "    return buenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Another violent and aggressive immigrant killing a innocent and intelligent US Citizen.... Sarcasm'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = data_train.iloc[0]\n",
    "print(row.spans)\n",
    "row.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    }
   ],
   "source": [
    "print(quitar_espacios_de_spans(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quitando puntuaci√≥n\n",
    "\n",
    "No es tan trivial el solamente eliminar la puntuaci√≥n y cosas raras, tal como se hizo al inicio al momento de querer el vocabulario. Se debe registrar donde se est√°n eliminando cosas para luego ver si eso era parte de un toxic span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_caracteres(row):\n",
    "    #toxico = obtener_texto_toxico(row)\n",
    "    #toxic_span = \"\".join(toxico) # juntar texto t√≥xico\n",
    "    strange_chars = set(re.findall(r\"[^\\w\\-*&#'¬ø?¬°!%`<>]\", row.text)) # encontrar cosas que no son letras, n√∫meros o gui√≥n bajo\n",
    "    # Inicializaci√≥n\n",
    "    offsets_filtrado = row.spans\n",
    "    texto_filtrado = row.text\n",
    "    indices = []\n",
    "    \n",
    "    for extra√±o in strange_chars: # Si no hay nada en toxic_match, no se itera\n",
    "        extra√±o = re.escape(extra√±o) # escapando posibles caracteres con interpretaci√≥n RegEx            \n",
    "        extra√±o_matchs = re.finditer(extra√±o, row.text)  # busca los caracteres raros\n",
    "        indices += [i.start() for i in extra√±o_matchs] # √çndices de caracteres en el texto\n",
    "        \n",
    "    if indices:\n",
    "        indices = set(indices)\n",
    "        spans_malos = indices & set(row.spans)\n",
    "        offsets_filtrado = [i for i in row.spans if i not in spans_malos] # filtrando\n",
    "        texto_filtrado = [c for i,c in enumerate(row.text) if i not in indices or c == \" \"]\n",
    "        texto_filtrado = \"\".join(texto_filtrado)\n",
    "            \n",
    "    return offsets_filtrado, texto_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106, 107, 108, 109, 110, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182]\n",
      "Who is this \"we\" of which you speak? Are you really a woman, Lars? If not then concern yourself with your penis and other genital and reproductive parts and stay out of women's bodies.\n"
     ]
    }
   ],
   "source": [
    "row = data_train.loc[7938]\n",
    "print(row.spans)\n",
    "print(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([106, 107, 108, 109, 110, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182], \"Who is this we of which you speak? Are you really a woman Lars? If not then concern yourself with your penis and other genital and reproductive parts and stay out of women's bodies\")\n"
     ]
    }
   ],
   "source": [
    "print(eliminar_caracteres(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrigiendo errores de los pendejos que subrayaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_spans_toxicos(row):\n",
    "    lists = []\n",
    "    start = row.spans[0]\n",
    "    end = row.spans[0]\n",
    "    for i in range(1, len(row.spans)):\n",
    "        #print(row.spans[i])\n",
    "        end = row.spans[i]\n",
    "        previous = row.spans[i-1] \n",
    "        if (end - previous) != 1: # Termin√≥ un span, inici√≥ el otro\n",
    "            lists.append(list(range(start,previous+1)))\n",
    "            start = end\n",
    "    \n",
    "    # Agregando √∫ltimo span\n",
    "    lists.append(list( range(start, end+1) ))\n",
    "            \n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_mamadas(row, umbral):\n",
    "    lista_palabras = row.text.split()\n",
    "    starts, ends = [], []\n",
    "    start, end = 0, -2\n",
    "    for idx, palabra in enumerate(lista_palabras):\n",
    "        starts.append(start) # start actual\n",
    "        start += len(palabra) + 1 # start para la siguiente\n",
    "        end   += len(palabra) + 1 # end actual\n",
    "        ends.append(end)\n",
    "    \n",
    "    toxicos = []\n",
    "    if row.spans:\n",
    "        indices_separados = separar_spans_toxicos(row)\n",
    "        for separado in indices_separados: # iterando partes t√≥xicas \n",
    "            indices = separado\n",
    "            for s, e in zip(starts, ends): # iterando \"texto\" por medio de los √≠ndices de palabras\n",
    "                if separado[0] in range(s,e+1): # span est√° en una palabra\n",
    "                    if separado != list(range(s, e+1)): # los spans no abarca toda la palabra\n",
    "                        #print(row.text[s:e+1])\n",
    "                        if len(separado)/(len(list(range(s, e+1)))) <= umbral:\n",
    "                            #print(\"No ser√° marcado\\n\")\n",
    "                            indices = [] # mejor ni lo marques\n",
    "                        else:\n",
    "                            #print(\"Ser√° marcado en su totalidad\")\n",
    "                            indices = list(range(s, e+1)) # ya m√°rcate todo mejor\n",
    "                    else:\n",
    "                        break # la palabra est√° bien marcada, pasa a la siguiente parte t√≥xica\n",
    "            toxicos.extend(indices)\n",
    "    return toxicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando con el ejemplo de Tradeu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Trudeau is full of crap. The truth is he only lost interest in electoral reform when it was pointed out to His Royal Anus that it wouldn't give the Liberals the unfair advantage he sought.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = data_train.iloc[218]\n",
    "print(row.spans)\n",
    "row.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 9, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146, 148, 149]\n"
     ]
    }
   ],
   "source": [
    "row.spans = quitar_espacios_de_spans(row)\n",
    "print(row.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146]\n"
     ]
    }
   ],
   "source": [
    "# Antes: Sobran el √≠ndice 6, el 148 y el 149\n",
    "print(corregir_mamadas(row, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora s√≠ en general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(row):\n",
    "    offsets, texto = eliminar_caracteres(row)\n",
    "    new_row = pd.Series([offsets, texto], index=row.index)\n",
    "    new_row.spans = corregir_mamadas(new_row, 0.75)\n",
    "    new_row.text = new_row.text.lower()\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(row):\n",
    "    offsets = quitar_espacios_de_spans(row)\n",
    "    new_row = pd.Series([offsets, row.text.lower()], index=row.index)\n",
    "    new_row.spans = corregir_mamadas(new_row, 0.75)\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = data_train.apply(preprocesar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...</td>\n",
       "      <td>another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>i am 56 years old i am not your fucking junior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>damn a whole family sad indeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>what a knucklehead how can anyone not know thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>who do you think should do the killing?anyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>another fool pipes in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 6...</td>\n",
       "      <td>so if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>this idiotic use the surplus to pay down the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[103, 104, 105, 106, 107, 166, 167, 168, 169, ...</td>\n",
       "      <td>who is this we of which you speak? are you rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "0     [8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...   \n",
       "1                          [32, 33, 34, 35, 36, 37, 38]   \n",
       "2                                          [0, 1, 2, 3]   \n",
       "3             [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 6...   \n",
       "7936  [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...   \n",
       "7937                            [5, 6, 7, 8, 9, 10, 11]   \n",
       "7938  [103, 104, 105, 106, 107, 166, 167, 168, 169, ...   \n",
       "\n",
       "                                                   text  \n",
       "0     another violent and aggressive immigrant killi...  \n",
       "1     i am 56 years old i am not your fucking junior...  \n",
       "2                        damn a whole family sad indeed  \n",
       "3     what a knucklehead how can anyone not know thi...  \n",
       "4     who do you think should do the killing?anyone ...  \n",
       "...                                                 ...  \n",
       "7934                              another fool pipes in  \n",
       "7935  so if a restaurant owner puts up a sign saying...  \n",
       "7936  any faith that can't stand up to logic and rea...  \n",
       "7937  this idiotic use the surplus to pay down the p...  \n",
       "7938  who is this we of which you speak? are you rea...  \n",
       "\n",
       "[7939 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se ven diferencias porque hab√≠an pocas de estas situaciones, o al menos s√≥lo observamos una, la de Tradeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.to_csv(\"../data/train_cleaned_exp.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial.spans = data_trial.spans.apply(procesar_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_cleaned = data_trial.apply(preprocesar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial.to_csv(\"../data/trial_cleaned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetado POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('own', 'VB'),\n",
       " ('stock', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('Trump', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Russian', 'JJ'),\n",
       " ('enterprises', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('not', 'RB'),\n",
       " ('care', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('presidential', 'JJ'),\n",
       " ('election', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('hijacked', 'VBN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "text = nltk.word_tokenize(\"Do you own stock in one of Trump's Russian enterprises or do you just not care that a presidential election was hijacked? \")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.pos_tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.pos_tag_sents?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
