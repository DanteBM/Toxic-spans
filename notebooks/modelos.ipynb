{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger, HiddenMarkovModelTrainer\n",
    "from utils import leer_csv, starts_ends_tokens, separar_spans_toxicos\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...</td>\n",
       "      <td>another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>i am 56 years old, i am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>damn, a whole family. sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]</td>\n",
       "      <td>what a knucklehead. how can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38, 39, 40]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>another fool pipes in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 6...</td>\n",
       "      <td>so if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>this idiotic. use the surplus to pay down the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[106, 107, 108, 109, 110, 169, 170, 171, 172, ...</td>\n",
       "      <td>who is this \"we\" of which you speak? are you r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "0     [8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...   \n",
       "1                          [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3, 4]   \n",
       "3         [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]   \n",
       "4                  [32, 33, 34, 35, 36, 37, 38, 39, 40]   \n",
       "...                                                 ...   \n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 6...   \n",
       "7936  [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...   \n",
       "7937                        [5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...   \n",
       "\n",
       "                                                   text  \n",
       "0     another violent and aggressive immigrant killi...  \n",
       "1     i am 56 years old, i am not your fucking junio...  \n",
       "2                     damn, a whole family. sad indeed.  \n",
       "3     what a knucklehead. how can anyone not know th...  \n",
       "4     \"who do you think should do the killing?\"\\n\\na...  \n",
       "...                                                 ...  \n",
       "7934                             another fool pipes in.  \n",
       "7935  so if a restaurant owner puts up a sign saying...  \n",
       "7936  any faith that can't stand up to logic and rea...  \n",
       "7937  this idiotic. use the surplus to pay down the ...  \n",
       "7938  who is this \"we\" of which you speak? are you r...  \n",
       "\n",
       "[7939 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = leer_csv(\"../data/train_cleaned.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener secuencias etiquetas\n",
    "\n",
    "(palabra1,tag1), (palabra2,tag2),..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar_secuencia(row):\n",
    "    word_starts, word_ends = starts_ends_tokens(row.text)\n",
    "    toxic_spans = separar_spans_toxicos(row)\n",
    "    toxic_starts = [span[0] for span in toxic_spans]\n",
    "    toxic_ends = [span[-1] for span in toxic_spans]\n",
    "    \n",
    "    secuencia = []\n",
    "    \n",
    "    for word_start, word_end in zip(word_starts, word_ends):\n",
    "        tag = \"T\" if word_start in toxic_starts and word_end in toxic_ends else \"N\"\n",
    "        secuencia.append(tag)\n",
    "        \n",
    "    secuencia = list(zip(row.text.split(), secuencia))\n",
    "            \n",
    "    return secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('another', 'N'),\n",
       " ('violent', 'T'),\n",
       " ('and', 'T'),\n",
       " ('aggressive', 'T'),\n",
       " ('immigrant', 'T'),\n",
       " ('killing', 'N'),\n",
       " ('a', 'N'),\n",
       " ('innocent', 'N'),\n",
       " ('and', 'N'),\n",
       " ('intelligent', 'N'),\n",
       " ('us', 'N'),\n",
       " ('citizen....', 'N'),\n",
       " ('sarcasm', 'N')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetar_secuencia(train_data.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "    tokens = df[\"text\"].apply(str.split)\n",
    "    vocab = set()\n",
    "    for i,row in tokens.iteritems():\n",
    "        vocab |= set(row)\n",
    "    return vocab\n",
    "\n",
    "vocab = get_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [etiquetar_secuencia(row) for row in train_data.itertuples()]\n",
    "\n",
    "trainer = HiddenMarkovModelTrainer(states=[\"T\", \"N\"], symbols=vocab)\n",
    "\n",
    "model = trainer.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['another',\n",
       " 'violent',\n",
       " 'and',\n",
       " 'aggressive',\n",
       " 'immigrant',\n",
       " 'killing',\n",
       " 'a',\n",
       " 'innocent',\n",
       " 'and',\n",
       " 'intelligent',\n",
       " 'us',\n",
       " 'citizen....',\n",
       " 'sarcasm']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = train_data.loc[0,\"text\"].split()\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('another', 'N'),\n",
       " ('violent', 'T'),\n",
       " ('and', 'T'),\n",
       " ('aggressive', 'T'),\n",
       " ('immigrant', 'T'),\n",
       " ('killing', 'N'),\n",
       " ('a', 'N'),\n",
       " ('innocent', 'N'),\n",
       " ('and', 'N'),\n",
       " ('intelligent', 'N'),\n",
       " ('us', 'N'),\n",
       " ('citizen....', 'N'),\n",
       " ('sarcasm', 'N')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('another', 'T'),\n",
       " ('violent', 'T'),\n",
       " ('and', 'T'),\n",
       " ('aggressive', 'T'),\n",
       " ('immigrant', 'T'),\n",
       " ('killing', 'T'),\n",
       " ('a', 'N'),\n",
       " ('innocent', 'N'),\n",
       " ('and', 'N'),\n",
       " ('intelligent', 'N'),\n",
       " ('us', 'N'),\n",
       " ('citizen....', 'N'),\n",
       " ('sarcasm', 'N')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = model.tag(comment)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags2offsets(tagged_comment):\n",
    "    words = [word for word,tag in tagged_comment]\n",
    "    tags = [tag for word, tag in tagged_comment]\n",
    "    \n",
    "    text = \" \".join(words)\n",
    "    starts, ends = starts_ends_tokens(text)\n",
    "    offsets = []\n",
    "    for i, (word, tag) in enumerate(tagged_comment):\n",
    "        if tag == \"T\":\n",
    "            offsets.extend(list( range(starts[i], ends[i]+1)) )\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_offsets = tags2offsets(tagged)\n",
    "system_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(system_offsets, ground_truth):\n",
    "    if ground_truth:\n",
    "        system_offsets = set(system_offsets)\n",
    "        ground_truth = set(ground_truth)\n",
    "\n",
    "        interseccion = system_offsets & ground_truth\n",
    "        precision = len(interseccion)/len(system_offsets) if system_offsets else 0\n",
    "        recall = len(interseccion)/len(ground_truth)\n",
    "        f1 = (2*precision*recall)/(precision+recall) if (precision,recall) != (0,0) else 0\n",
    "        \n",
    "    elif system_offsets:\n",
    "        f1 = 0 # no hay verdaderas, pero hay en la predicción, se define como 0\n",
    "    else:\n",
    "        f1 = 1\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055555555555556"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(system_offsets, train_data.loc[0,\"spans\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_text = train_data.text.apply(str.split)\n",
    "tagged_train_text = tokenized_train_text.apply(model.tag)\n",
    "\n",
    "train_offsets = tagged_train_text.apply(tags2offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5665808284065257"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = [f1_score(system_offsets, ground_truth) \n",
    "                for system_offsets, ground_truth in zip(train_offsets, train_data.spans)]\n",
    "np.mean(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = leer_csv(\"../data/trial_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23340335538403886"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_test = trial_data.text.apply(str.split)\n",
    "tagged_test_text = tokenized_test_test.apply(model.tag)\n",
    "\n",
    "test_offsets = tagged_test_text.apply(tags2offsets)\n",
    "\n",
    "test_scores = [f1_score(system_offsets, ground_truth) \n",
    "                for system_offsets, ground_truth in zip(test_offsets, trial_data.spans)]\n",
    "np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error en la implementación de F1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenando con todo, literalmente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7939, 2) (690, 2)\n"
     ]
    }
   ],
   "source": [
    "train = leer_csv(\"../data/train_cleaned.csv\")\n",
    "trial = leer_csv(\"../data/trial_cleaned.csv\")\n",
    "print(train.shape, trial.shape)\n",
    "todo = pd.concat([train, trial], ignore_index = True)\n",
    "todo.to_csv(\"../data/tsd_completo.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [etiquetar_secuencia(row) for row in todo.itertuples()]\n",
    "\n",
    "vocab = get_vocab(todo)\n",
    "trainer = HiddenMarkovModelTrainer(states=[\"T\", \"N\"], symbols=vocab)\n",
    "\n",
    "model = trainer.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = todo.text.apply(str.split)\n",
    "tagged_text = tokenized_text.apply(model.tag)\n",
    "\n",
    "system_offsets = tagged_text.apply(tags2offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4600794289527663"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = [f1_score(offsets, ground_truth) \n",
    "                for offsets, ground_truth in zip(system_offsets, todo.spans)]\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8629, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>[129, 130, 131, 132, 133, 134]</td>\n",
       "      <td>But ... Trump's not bluffing. He's prepared to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>[126, 127, 128, 129, 130, 131]</td>\n",
       "      <td>Can't believe the limited knowledge of this Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>[24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>I think it conservative idiots who cannot reac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>You're an id*ot...Go away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "      <td>Unless there is wording in the employment cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 spans  \\\n",
       "0             [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                             [29, 30, 31, 32, 33, 34]   \n",
       "2                       [166, 167, 168, 169, 170, 171]   \n",
       "3                             [87, 88, 89, 90, 91, 92]   \n",
       "4                                                   []   \n",
       "..                                                 ...   \n",
       "685                     [129, 130, 131, 132, 133, 134]   \n",
       "686                     [126, 127, 128, 129, 130, 131]   \n",
       "687                           [24, 25, 26, 27, 28, 29]   \n",
       "688  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "689                     [136, 137, 138, 139, 140, 141]   \n",
       "\n",
       "                                                  text  \n",
       "0    Because he's a moron and a bigot. It's not any...  \n",
       "1    How about we stop protecting idiots and let na...  \n",
       "2    If people  were  smart, they would  Boycott th...  \n",
       "3    Trump Claimed that Russia will never invade th...  \n",
       "4    As long as your willing to pay a lot more for ...  \n",
       "..                                                 ...  \n",
       "685  But ... Trump's not bluffing. He's prepared to...  \n",
       "686  Can't believe the limited knowledge of this Ar...  \n",
       "687  I think it conservative idiots who cannot reac...  \n",
       "688                         You're an id*ot...Go away.  \n",
       "689  Unless there is wording in the employment cont...  \n",
       "\n",
       "[690 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9200370842507822"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 690/8629"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6471, 2) (2158, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(todo, test_size=0.25, random_state=42)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_vocab(train)\n",
    "train_sentences = [etiquetar_secuencia(row) for row in train.itertuples()]\n",
    "trainer = HiddenMarkovModelTrainer(states=[\"T\", \"N\"], symbols=vocab)\n",
    "model = trainer.train(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_f1(df, model):\n",
    "    tokenized_text = df.text.apply(str.split)\n",
    "    tagged_text = tokenized_text.apply(model.tag)\n",
    "\n",
    "    system_offsets = tagged_text.apply(tags2offsets)\n",
    "    print(df.shape, system_offsets.shape)\n",
    "    scores = [f1_score(offsets, ground_truth) \n",
    "                for offsets, ground_truth in zip(system_offsets, df.spans)]\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6471, 2) (6471,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.516266133717116"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtener_f1(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2158, 2) (2158,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2635414212492578"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtener_f1(test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd_test = pd.read_csv(\"../data/tsd_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd_test.text = tsd_test.text.str.lower()\n",
    "tokenized = tsd_test.text.apply(str.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = tokenized.apply(model.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.apply(tags2offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/spans-pred.txt\", sep=\"\\t\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
