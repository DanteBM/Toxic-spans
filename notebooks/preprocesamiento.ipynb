{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n",
       "      <td>Because he's a moron and a bigot. It's not any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[29, 30, 31, 32, 33, 34]</td>\n",
       "      <td>How about we stop protecting idiots and let na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[166, 167, 168, 169, 170, 171]</td>\n",
       "      <td>If people  were  smart, they would  Boycott th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[87, 88, 89, 90, 91, 92]</td>\n",
       "      <td>Trump Claimed that Russia will never invade th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>As long as your willing to pay a lot more for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_trial = pd.read_csv(\"../data/tsd_trial.csv\")\n",
    "print(data_trial.shape)\n",
    "data_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7939, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
       "      <td>Another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>Damn, a whole family. Sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>What a knucklehead. How can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>Another fool pipes in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...</td>\n",
       "      <td>So if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>Any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>This idiotic. Use the surplus to pay down the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[106, 107, 108, 109, 110, 169, 170, 171, 172, ...</td>\n",
       "      <td>Who is this \"we\" of which you speak? Are you r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "0     [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                          [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                          [0, 1, 2, 3]   \n",
       "3             [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                          [32, 33, 34, 35, 36, 37, 38]   \n",
       "...                                                 ...   \n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...   \n",
       "7936  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "7937                            [5, 6, 7, 8, 9, 10, 11]   \n",
       "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...   \n",
       "\n",
       "                                                   text  \n",
       "0     Another violent and aggressive immigrant killi...  \n",
       "1     I am 56 years old, I am not your fucking junio...  \n",
       "2                     Damn, a whole family. Sad indeed.  \n",
       "3     What a knucklehead. How can anyone not know th...  \n",
       "4     \"who do you think should do the killing?\"\\n\\nA...  \n",
       "...                                                 ...  \n",
       "7934                             Another fool pipes in.  \n",
       "7935  So if a restaurant owner puts up a sign saying...  \n",
       "7936  Any faith that can't stand up to logic and rea...  \n",
       "7937  This idiotic. Use the surplus to pay down the ...  \n",
       "7938  Who is this \"we\" of which you speak? Are you r...  \n",
       "\n",
       "[7939 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"../data/tsd_train.csv\")\n",
    "print(data_train.shape)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8629, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data_trial, data_train])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que había solamente cinco textos repetidos. \n",
    "\n",
    "Se usará `tsd_train.csv` para entrenar y `tsd_trial` para validación\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alfabeto\n",
    "\n",
    "Vendría bien conocer que símbolos hay en los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjuntos = data_train.text.agg(set)\n",
    "alfabeto = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '}',\n",
       " '~',\n",
       " '\\x7f',\n",
       " '\\xa0',\n",
       " '«',\n",
       " '¬',\n",
       " '·',\n",
       " '»',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'ï',\n",
       " 'ó',\n",
       " 'ü',\n",
       " 'ʻ',\n",
       " 'ˈ',\n",
       " '͞',\n",
       " '\\u2004',\n",
       " '\\u200b',\n",
       " '–',\n",
       " '—',\n",
       " '―',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '•',\n",
       " '…',\n",
       " '™',\n",
       " '▀',\n",
       " '☠',\n",
       " '☭',\n",
       " '☹',\n",
       " '⚽',\n",
       " '⚾',\n",
       " '✭',\n",
       " '️',\n",
       " '🆘',\n",
       " '👎',\n",
       " '💀',\n",
       " '💥',\n",
       " '💨',\n",
       " '🔥',\n",
       " '😁',\n",
       " '😂',\n",
       " '😅',\n",
       " '😆',\n",
       " '😈',\n",
       " '😉',\n",
       " '😊',\n",
       " '😜',\n",
       " '😞',\n",
       " '😡',\n",
       " '😬',\n",
       " '😵',\n",
       " '🙄',\n",
       " '🤥'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index,item in conjuntos.iteritems():\n",
    "    alfabeto |= item\n",
    "\n",
    "alfabeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alfabeto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparte del abecedario, tenemos algunos símbolos que se usan con relativa frecuencia en internet.\n",
    "\n",
    "Sin embargo, también notamos que hay caracteres raros como las comillas dobles, guiones con sus variantes, etc. También hay que notar que hay emojis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulario\n",
    "\n",
    "Para obtener el vocabulario, es necesario realizar un preprocesamiento a los textos, esto incluye:\n",
    "* sustituir minúsculas\n",
    "* quitar emojis\n",
    "* ¿quitar caracteres raros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar(texto):\n",
    "    texto = texto.lower() #minúsculas\n",
    "    texto = re.sub(\"[\\W_]\", \" \", texto) #carácteres raros\n",
    "    texto = re.sub(\"\\s+\", \" \", texto) # colapsando espaciados\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another violent and aggressive immigrant killing a innocent and intelligent US Citizen.... Sarcasm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data_train.text[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'another violent and aggressive immigrant killing a innocent and intelligent us citizen sarcasm'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_preprocesado = data_train.text.apply(limpiar)\n",
    "\n",
    "texto_tokenizado = texto_preprocesado.apply(str.split)\n",
    "\n",
    "vocabulario = set()\n",
    "for index, lista in texto_tokenizado.iteritems():\n",
    "    vocabulario |= set(lista)\n",
    "\n",
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento\n",
    "\n",
    "Vamos a obtener el texto que se ha considerado como tóxico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_span(span):\n",
    "    span = re.sub(\"\\s\",\"\",span[1:-1])\n",
    "    if span:\n",
    "        lista = span.split(\",\")\n",
    "        lista = [int(index) for index in lista]\n",
    "    else:\n",
    "        lista = []\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"spans\"] = data_train[\"spans\"].apply(procesar_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_texto_toxico(row):\n",
    "    toxico = []\n",
    "    if row.spans: # Hay texto marcado como toxico\n",
    "        diffs = np.diff(row.spans, prepend=row.spans[0]-1) #prepend para que el primer diff sea uno\n",
    "        toxico = []\n",
    "        indices_inicios = np.argwhere(diffs != 1).ravel() # indices de los inicios de las sigs palabras\n",
    "\n",
    "        i = row.spans[0]\n",
    "        for indice_next in indices_inicios:\n",
    "            j = row.spans[indice_next-1] # fin de la anterior\n",
    "            parte_toxica = row.text[i:j+1]\n",
    "            toxico.append(parte_toxica)\n",
    "            i = row.spans[indice_next]\n",
    "            \n",
    "        # Última parte\n",
    "        j = row.spans[-1]\n",
    "        parte_toxica = row.text[i:j+1]\n",
    "        toxico.append(parte_toxica)\n",
    "\n",
    "    return toxico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quitando espacios de los tramos tóxicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quitar_espacios_de_spans(row):\n",
    "    toxico = obtener_texto_toxico(row)\n",
    "    toxic_span = \"\".join(toxico) # juntar texto tóxico\n",
    "    toxic_match = set(re.findall(r\"\\W\", toxic_span)) # encontrar cosas que no son letras, números o guión bajo\n",
    "    # Inicialización\n",
    "    buenos = row.spans\n",
    "    indices = []\n",
    "    \n",
    "    for extraño in toxic_match: # Si no hay nada en toxic_match, no se itera\n",
    "        extraño = re.escape(extraño) # escapando posibles caracteres con interpretación RegEx\n",
    "        if extraño == \"\\ \":\n",
    "            indice = re.finditer(extraño, toxic_span) \n",
    "            indices = [i.start() for i in indice] # Índices de espacios en el texto\n",
    "    if indices:\n",
    "        por_quitar = [row.spans[i] for i in indices] # spans tóxicos que son espacios\n",
    "        buenos = [i for i in row.spans if i not in por_quitar] # filtrando\n",
    "            \n",
    "    return buenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Another violent and aggressive immigrant killing a innocent and intelligent US Citizen.... Sarcasm'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = data_train.iloc[0]\n",
    "print(row.spans)\n",
    "row.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    }
   ],
   "source": [
    "print(quitar_espacios_de_spans(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quitando puntuación\n",
    "\n",
    "No es tan trivial el solamente eliminar la puntuación y cosas raras, tal como se hizo al inicio al momento de querer el vocabulario. Se debe registrar donde se están eliminando cosas para luego ver si eso era parte de un toxic span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_caracteres(row):\n",
    "    #toxico = obtener_texto_toxico(row)\n",
    "    #toxic_span = \"\".join(toxico) # juntar texto tóxico\n",
    "    strange_chars = set(re.findall(r\"[^\\w\\-*&#'¿?¡!%`<>]\", row.text)) # encontrar cosas que no son letras, números o guión bajo\n",
    "    # Inicialización\n",
    "    offsets_filtrado = row.spans\n",
    "    texto_filtrado = row.text\n",
    "    indices = []\n",
    "    \n",
    "    for extraño in strange_chars: # Si no hay nada en toxic_match, no se itera\n",
    "        extraño = re.escape(extraño) # escapando posibles caracteres con interpretación RegEx            \n",
    "        extraño_matchs = re.finditer(extraño, row.text)  # busca los caracteres raros\n",
    "        indices += [i.start() for i in extraño_matchs] # Índices de caracteres en el texto\n",
    "        \n",
    "    if indices:\n",
    "        indices = set(indices)\n",
    "        spans_malos = indices & set(row.spans)\n",
    "        offsets_filtrado = [i for i in row.spans if i not in spans_malos] # filtrando\n",
    "        texto_filtrado = [c for i,c in enumerate(row.text) if i not in indices or c == \" \"]\n",
    "        texto_filtrado = \"\".join(texto_filtrado)\n",
    "            \n",
    "    return offsets_filtrado, texto_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106, 107, 108, 109, 110, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182]\n",
      "Who is this \"we\" of which you speak? Are you really a woman, Lars? If not then concern yourself with your penis and other genital and reproductive parts and stay out of women's bodies.\n"
     ]
    }
   ],
   "source": [
    "row = data_train.loc[7938]\n",
    "print(row.spans)\n",
    "print(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([106, 107, 108, 109, 110, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 182], \"Who is this we of which you speak? Are you really a woman Lars? If not then concern yourself with your penis and other genital and reproductive parts and stay out of women's bodies\")\n"
     ]
    }
   ],
   "source": [
    "print(eliminar_caracteres(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrigiendo errores de los pendejos que subrayaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_spans_toxicos(row):\n",
    "    lists = []\n",
    "    start = row.spans[0]\n",
    "    end = row.spans[0]\n",
    "    for i in range(1, len(row.spans)):\n",
    "        #print(row.spans[i])\n",
    "        end = row.spans[i]\n",
    "        previous = row.spans[i-1] \n",
    "        if (end - previous) != 1: # Terminó un span, inició el otro\n",
    "            lists.append(list(range(start,previous+1)))\n",
    "            start = end\n",
    "    \n",
    "    # Agregando último span\n",
    "    lists.append(list( range(start, end+1) ))\n",
    "            \n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_mamadas(row, umbral):\n",
    "    lista_palabras = row.text.split()\n",
    "    starts, ends = [], []\n",
    "    start, end = 0, -2\n",
    "    for idx, palabra in enumerate(lista_palabras):\n",
    "        starts.append(start) # start actual\n",
    "        start += len(palabra) + 1 # start para la siguiente\n",
    "        end   += len(palabra) + 1 # end actual\n",
    "        ends.append(end)\n",
    "    \n",
    "    toxicos = []\n",
    "    if row.spans:\n",
    "        indices_separados = separar_spans_toxicos(row)\n",
    "        for separado in indices_separados: # iterando partes tóxicas \n",
    "            indices = separado\n",
    "            for s, e in zip(starts, ends): # iterando \"texto\" por medio de los índices de palabras\n",
    "                if separado[0] in range(s,e+1): # span está en una palabra\n",
    "                    if separado != list(range(s, e+1)): # los spans no abarca toda la palabra\n",
    "                        #print(row.text[s:e+1])\n",
    "                        if len(separado)/(len(list(range(s, e+1)))) <= umbral:\n",
    "                            #print(\"No será marcado\\n\")\n",
    "                            indices = [] # mejor ni lo marques\n",
    "                        else:\n",
    "                            #print(\"Será marcado en su totalidad\")\n",
    "                            indices = list(range(s, e+1)) # ya márcate todo mejor\n",
    "                    else:\n",
    "                        break # la palabra está bien marcada, pasa a la siguiente parte tóxica\n",
    "            toxicos.extend(indices)\n",
    "    return toxicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando con el ejemplo de Tradeu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Trudeau is full of crap. The truth is he only lost interest in electoral reform when it was pointed out to His Royal Anus that it wouldn't give the Liberals the unfair advantage he sought.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = data_train.iloc[218]\n",
    "print(row.spans)\n",
    "row.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 9, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146, 148, 149]\n"
     ]
    }
   ],
   "source": [
    "row.spans = quitar_espacios_de_spans(row)\n",
    "print(row.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146]\n"
     ]
    }
   ],
   "source": [
    "# Antes: Sobran el índice 6, el 148 y el 149\n",
    "print(corregir_mamadas(row, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora sí en general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(row):\n",
    "    offsets, texto = eliminar_caracteres(row)\n",
    "    new_row = pd.Series([offsets, texto], index=row.index)\n",
    "    new_row.spans = corregir_mamadas(new_row, 0.75)\n",
    "    new_row.text = new_row.text.lower()\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(row):\n",
    "    offsets = quitar_espacios_de_spans(row)\n",
    "    new_row = pd.Series([offsets, row.text.lower()], index=row.index)\n",
    "    new_row.spans = corregir_mamadas(new_row, 0.75)\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = data_train.apply(preprocesar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...</td>\n",
       "      <td>another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
       "      <td>i am 56 years old i am not your fucking junior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>damn a whole family sad indeed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
       "      <td>what a knucklehead how can anyone not know thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>who do you think should do the killing?anyone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>another fool pipes in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 6...</td>\n",
       "      <td>so if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>this idiotic use the surplus to pay down the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[103, 104, 105, 106, 107, 166, 167, 168, 169, ...</td>\n",
       "      <td>who is this we of which you speak? are you rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "0     [8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...   \n",
       "1                          [32, 33, 34, 35, 36, 37, 38]   \n",
       "2                                          [0, 1, 2, 3]   \n",
       "3             [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 6...   \n",
       "7936  [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...   \n",
       "7937                            [5, 6, 7, 8, 9, 10, 11]   \n",
       "7938  [103, 104, 105, 106, 107, 166, 167, 168, 169, ...   \n",
       "\n",
       "                                                   text  \n",
       "0     another violent and aggressive immigrant killi...  \n",
       "1     i am 56 years old i am not your fucking junior...  \n",
       "2                        damn a whole family sad indeed  \n",
       "3     what a knucklehead how can anyone not know thi...  \n",
       "4     who do you think should do the killing?anyone ...  \n",
       "...                                                 ...  \n",
       "7934                              another fool pipes in  \n",
       "7935  so if a restaurant owner puts up a sign saying...  \n",
       "7936  any faith that can't stand up to logic and rea...  \n",
       "7937  this idiotic use the surplus to pay down the p...  \n",
       "7938  who is this we of which you speak? are you rea...  \n",
       "\n",
       "[7939 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se ven diferencias porque habían pocas de estas situaciones, o al menos sólo observamos una, la de Tradeu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.to_csv(\"../data/train_cleaned_exp.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial.spans = data_trial.spans.apply(procesar_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_cleaned = data_trial.apply(preprocesar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trial.to_csv(\"../data/trial_cleaned.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetado POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('own', 'VB'),\n",
       " ('stock', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('Trump', 'NNP'),\n",
       " (\"'s\", 'POS'),\n",
       " ('Russian', 'JJ'),\n",
       " ('enterprises', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('not', 'RB'),\n",
       " ('care', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('presidential', 'JJ'),\n",
       " ('election', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('hijacked', 'VBN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "text = nltk.word_tokenize(\"Do you own stock in one of Trump's Russian enterprises or do you just not care that a presidential election was hijacked? \")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.pos_tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.pos_tag_sents?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
