{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger, HiddenMarkovModelTrainer\n",
    "from utils import leer_csv, starts_ends_tokens, separar_spans_toxicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...</td>\n",
       "      <td>another violent and aggressive immigrant killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
       "      <td>i am 56 years old, i am not your fucking junio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>damn, a whole family. sad indeed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]</td>\n",
       "      <td>what a knucklehead. how can anyone not know th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[32, 33, 34, 35, 36, 37, 38, 39, 40]</td>\n",
       "      <td>\"who do you think should do the killing?\"\\n\\na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>another fool pipes in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 6...</td>\n",
       "      <td>so if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...</td>\n",
       "      <td>any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>this idiotic. use the surplus to pay down the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[106, 107, 108, 109, 110, 169, 170, 171, 172, ...</td>\n",
       "      <td>who is this \"we\" of which you speak? are you r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "0     [8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21,...   \n",
       "1                          [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3, 4]   \n",
       "3         [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]   \n",
       "4                  [32, 33, 34, 35, 36, 37, 38, 39, 40]   \n",
       "...                                                 ...   \n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 6...   \n",
       "7936  [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 1...   \n",
       "7937                        [5, 6, 7, 8, 9, 10, 11, 12]   \n",
       "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...   \n",
       "\n",
       "                                                   text  \n",
       "0     another violent and aggressive immigrant killi...  \n",
       "1     i am 56 years old, i am not your fucking junio...  \n",
       "2                     damn, a whole family. sad indeed.  \n",
       "3     what a knucklehead. how can anyone not know th...  \n",
       "4     \"who do you think should do the killing?\"\\n\\na...  \n",
       "...                                                 ...  \n",
       "7934                             another fool pipes in.  \n",
       "7935  so if a restaurant owner puts up a sign saying...  \n",
       "7936  any faith that can't stand up to logic and rea...  \n",
       "7937  this idiotic. use the surplus to pay down the ...  \n",
       "7938  who is this \"we\" of which you speak? are you r...  \n",
       "\n",
       "[7939 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = leer_csv(\"../data/train_cleaned.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener secuencias etiquetas\n",
    "\n",
    "(palabra1,tag1), (palabra2,tag2),..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar_secuencia(row):\n",
    "    word_starts, word_ends = starts_ends_tokens(row.text)\n",
    "    toxic_spans = separar_spans_toxicos(row)\n",
    "    toxic_starts = [span[0] for span in toxic_spans]\n",
    "    toxic_ends = [span[-1] for span in toxic_spans]\n",
    "    \n",
    "    secuencia = []\n",
    "    \n",
    "    for word_start, word_end in zip(word_starts, word_ends):\n",
    "        tag = \"T\" if word_start in toxic_starts and word_end in toxic_ends else \"N\"\n",
    "        secuencia.append(tag)\n",
    "        \n",
    "    secuencia = list(zip(row.text.split(), secuencia))\n",
    "            \n",
    "    return secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('another', 'N'),\n",
       " ('violent', 'T'),\n",
       " ('and', 'T'),\n",
       " ('aggressive', 'T'),\n",
       " ('immigrant', 'T'),\n",
       " ('killing', 'N'),\n",
       " ('a', 'N'),\n",
       " ('innocent', 'N'),\n",
       " ('and', 'N'),\n",
       " ('intelligent', 'N'),\n",
       " ('us', 'N'),\n",
       " ('citizen....', 'N'),\n",
       " ('sarcasm', 'N')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiquetar_secuencia(train_data.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "    tokens = df[\"text\"].apply(str.split)\n",
    "    vocab = set()\n",
    "    for i,row in tokens.iteritems():\n",
    "        vocab |= set(row)\n",
    "    return vocab\n",
    "\n",
    "vocab = get_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [etiquetar_secuencia(row) for row in train_data.itertuples()]\n",
    "\n",
    "trainer = HiddenMarkovModelTrainer(states=[\"T\", \"N\"], symbols=vocab)\n",
    "\n",
    "model = trainer.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['another',\n",
       " 'violent',\n",
       " 'and',\n",
       " 'aggressive',\n",
       " 'immigrant',\n",
       " 'killing',\n",
       " 'a',\n",
       " 'innocent',\n",
       " 'and',\n",
       " 'intelligent',\n",
       " 'us',\n",
       " 'citizen....',\n",
       " 'sarcasm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment = train_data.loc[0,\"text\"].split()\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = model.tag(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags2offsets(tagged_comment):\n",
    "    words = [word for word,tag in tagged_comment]\n",
    "    tags = [tag for word, tag in tagged_comment]\n",
    "    \n",
    "    text = \" \".join(words)\n",
    "    starts, ends = starts_ends_tokens(text)\n",
    "    offsets = []\n",
    "    for i, (word, tag) in enumerate(tagged_comment):\n",
    "        if tag == \"T\":\n",
    "            offsets.extend(list( range(starts[i], ends[i]+1)) )\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_offsets = tags2offsets(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(system_offsets , ground_truth):\n",
    "    if ground_truth:\n",
    "        system_offsets = set(system_offsets)\n",
    "        ground_truth = set(ground_truth)\n",
    "\n",
    "        interseccion = system_offsets | ground_truth\n",
    "        precision = len(interseccion)/len(system_offsets) if system_offsets else 0\n",
    "        recall = len(interseccion)/len(ground_truth) if ground_truth else 0\n",
    "        f1 = (2*precision*recall)/(precision+recall)\n",
    "        \n",
    "    elif system_offsets:\n",
    "        f1 = 0 # no hay verdaderas, pero hay en la predicción, se define como 0\n",
    "    else:\n",
    "        f1 = 1 \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_text = train_data.text.apply(str.split)\n",
    "tagged_train_text = tokenized_train_text.apply(model.tag)\n",
    "\n",
    "train_offsets = tagged_train_text.apply(tags2offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8202437086888265"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores = [f1_score(system_offsets, ground_truth) \n",
    "                for system_offsets, ground_truth in zip(train_offsets, train_data.spans)]\n",
    "np.mean(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = leer_csv(\"../data/trial_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4416600298577078"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test_test = trial_data.text.apply(str.split)\n",
    "tagged_test_text = tokenized_test_test.apply(model.tag)\n",
    "\n",
    "test_offsets = tagged_test_text.apply(tags2offsets)\n",
    "\n",
    "test_scores = [f1_score(system_offsets, ground_truth) \n",
    "                for system_offsets, ground_truth in zip(test_offsets, trial_data.spans)]\n",
    "np.mean(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error en la implementación de F1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
